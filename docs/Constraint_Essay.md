# Project Constraint Essay

Our project, MedAssist, focuses on developing a mental health support chatbot that combines Retrieval-Augmented-Generation (RAG) and Large Language Models (LLMs). To ensure our project is feasible we must address several important constraints that will impact how our system is designed and deployed.

From an **economic** perspective, our largest limitations are API costs and computational resources. Since LLMs such as OpenAI's GPT models require paid tokens for both prompt inputs and generated outputs, continuous development and testing can quickly accumulate costs. This is especially relevant when the chatbot performs multiple retrievals or operations per query. Additionally, our system also relies on RAG, which requires generating and storing vector embeddings for similarity searches. This process is computationally intensive and can become quite costly when scaled. Since our team does not have access to high performance hardware, we are currently depending on free GPU resources such as Google Colab and Kaggle for model experimentation. These platforms, however, have session time limits and resource allocations that restrict large scale testing. To address this, we plan to optimize our code for efficiency and, if necessary, request temporary access to the university GPU server for more advanced experiments. If required, we could also rent cloud instances. These economic and computational constraints ultimately influence our system's architecture, encouraging lightweight model choices as well as careful and efficient resource management throughout development.

The next major constraint is **ethical**. As our chatbot engages users on mental health topics, data protection, privacy, and informed consent are crucial. We must ensure that all stored chat histories are securely handled and never reused for training purposes. Ethically, our chatbot cannot perform medical diagnoses or provide prescriptive advice. Its role is limited to offering emotional support, empathy, and appropriate resource referrals. The system's design must also prevent biased or insensitive responses and include clear disclaimers to remind users that it is not a substitute for licensed mental health professionals.

**Security** is another critical constraint that we need to consider. Because our platform interacts with sensitive user input, we must implement robust database encryption, API key protection, and measures to prevent prompt injection or unauthorized access. We must also ensure that external dependencies, including third-party APIs and open-source libraries, do not introduce vulnerabilities to our system. Maintaining these safeguards will help preserve user trust and ensure data integrity across all components of the system.

**Legal** constraints are also crucial. Since we will be making use of third-party APIs and open-source libraries, we must pay close attention to licensing restrictions as well as any sourcing requirements. Legal use is especially important when considering the dataset(s) our chatbot will be generating from. Steps must be taken on our end so that our chatbot does not misrepresent information. Careful use of disclaimers and making it clear to users that they are interacting with artificial intelligence rather than a human being is a must.

Finally, **social** and **cultural** considerations are also important. Our chatbot must use nonjudgmental and culturally aware language when addressing concerns. Since users may come from diverse backgrounds, we emphasize accessibility by keeping responses clear, empathetic, and easy to understand. By prioritizing cultural sensitivity and emotional awareness, our system aims to make mental health support more approachable and beneficial to a broader audience.
