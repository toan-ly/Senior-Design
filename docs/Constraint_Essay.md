# Project Constraint Essay

Our project, MedAssist, focuses on developing a mental health support chatbot that combines RAG and LLMs. To make it feasible, we must address several important constraints that can affect how the system is designed and deployed.

From an **economic** perspective, one of our largest limitations involves API costs and computational resources. Since LLMs such as OpenAI's GPT models require paid tokens for both prompt inputs and generated outputs, continuous development and testing can quickly accumulate costs, especially when the chatbot performs multiple retrieval or operations per query. Additionally, our system also relies on RAG, which requires generating and storing vector embeddings for similarity searches. This process is computationally intensive and can become costly when scaled. Since our team does not have access to high performance hardware, we are currently depending on free GPU resources such as Google Colab and Kaggle for model experimentation. These platforms, however, have session time limits and resource allocations that restrict large scale testing. To address this, we plan to optimize our code for efficiency and, if necessary, request temporary access to the university GPU server for more advanced experiments, or even try to rent cloud instances. These economic and computational constraints influence our system's architecture, encouraging lightweight model choices, careful and efficient resource management throughout development.

The next major constraint is **ethical**. As the chatbot engages users on mental health topics, data protection, privacy, and informed consent are crucial. We must ensure that all stored chat histories are securely handled and never reused for training purposes. Ethically, that chatbot cannot perform medical diagnoses or provide prescriptive advice. Its role is limited to offering emotional support, empathy, and appropriate resource referrals. The system's design must also prevent biased or insensitive responses and include clear disclaimers to remind users that it is not a substitute for licensed mental health professionals.

**Security** is another critical constraint that we need to consider. Because the platform interacts with sensitive user input, it must implement robust database encryption, API key protection, and measures to prevent prompt injection or unauthorized access. We must also ensure that external dependencies, including third-party APIs and open source libraries, do not introduce vulnerabilities to our system. Maintaining these safeguards will help preserve user trust and ensure data integrity across all components of the system.

Finally, **social** and **cultural** considerations are also important. The chatbot must use nonjudgmental and culturally aware language when addressing concerns. Since users may come from diverse backgrounds, we emphasize accessibility by keeping responses clear, empathetic, and easy to understand. By prioritizing cultural sensitivity and emotional awareness, our system aims to make mental health support more approachable and beneficial to a broader audience.
